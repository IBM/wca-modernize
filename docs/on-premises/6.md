# **Install IBM Software Hub**</br>*On-Premises Installation and Deployment*

!!! quote ""
    The following section is based off of IBM Documentation for <a href="https://www.ibm.com/docs/en/software-hub/5.1.x?topic=installing-preparing-install-instance-software-hub" target="_blank">**Preparing to install an instance of IBM Software Hub**</a>.

## **i. Install shared components**

Before an instance of IBM Software Hub can be installed, you need to install a set of shared services on the OpenShift Container Platform (OCP) cluster: a **license service** and a **scheduler**.

---

1. Three environment variables were set earlier in this lab, which are pertinent now to the license service (as well as the scheduler) that IBM Software Hub requires. These include:
    - `$PROJECT_LICENSE_SERVICE`
    - `$PROJECT_SCHEDULING_SERVICE`
    - `$VERSION`
    
    Refresh yourself on these variable's values by **executing** the following:

    ``` shell
    echo $PROJECT_LICENSE_SERVICE
    echo $PROJECT_SCHEDULING_SERVICE
    echo $VERSION
    ```

    These variables were defined within the **Cloud Pak for Data (CP4D) Environment Variable** (<a href="https://ibm.github.io/wca-l4/on-premises/3/#iv-environment-variables" target="_blank">**Step 8 of Module 3**</a>) on Lines 35, 36, and 53, respectively.

---

2. Install the **license service** components by executing the following command:

    ``` shell
    cpd-cli manage apply-cluster-components \
    --release=${VERSION} \
    --license_acceptance=true --licensing_ns=${PROJECT_LICENSE_SERVICE}
    ```

    !!! warning ""
        This operation will take approximately **10 minutes** to complete. After a successful operation, the console will return the following statements:
        ``` shell
        [âœ”] Cert manager is ready.
        [SUCCESS] 2025-03-19T18:58:58.400864Z You may find output and logs in the <REDACTED> directory.
        [SUCCESS] 2025-03-19T18:58:58.400949Z The apply-cluster-components command ran successfully.
        ```
    
    !!! tip ""
        **Record** the full directory address reported by the `[SUCCESS]` statement that reads `You may find output and logs in the...` directory. Save this information to a notepad for future reference.

---

3. Install the **scheduling service** by executing the following command:

    ``` shell
    cpd-cli manage apply-scheduler \
    --release=${VERSION} \
    --license_acceptance=true \
    --scheduler_ns=${PROJECT_SCHEDULING_SERVICE}
    ```

    !!! warning ""
        This operation will take approximately **10 minutes** to complete. After a successful operation, the console will return the following statements:
        ``` shell
        [SUCCESS] 2025-03-19T19:14:17.855196Z You may find output and logs in the <REDACTED> directory.
        [SUCCESS] 2025-03-19T19:14:17.855280Z The apply-scheduler command ran successfully.
        ```

---

## **ii. Install an instance of IBM Software Hub**

Finally, the cluster has been prepared to a state where it is ready to install an instance of IBM Software Hub. Although the following section requires relatively few inputs from the participant, it will take approximately **45 minutes** for the installation process to complete.

---

4. Create the two new projects that will host your instance by **executing** the following instructions within a Terminal console:

    ``` shell
    oc new-project ${PROJECT_CPD_INST_OPERATORS}
    oc new-project ${PROJECT_CPD_INST_OPERANDS}
    ```

---

5. **Apply** the required permissions for an instance of IBM Software Hub:

    ``` shell
    cpd-cli manage authorize-instance-topology \
    --cpd_operator_ns=${PROJECT_CPD_INST_OPERATORS} \
    --cpd_instance_ns=${PROJECT_CPD_INST_OPERANDS}
    ```
    !!! warning ""
        This operation will take approximately **2 minutes** to complete. After a successful operation, the console will return the following statements:
        ``` shell
        [SUCCESS] 2025-03-19T19:17:06.452627Z You may find output and logs in the <REDACTED> directory.
        [SUCCESS] 2025-03-19T19:17:06.453087Z The authorize-instance-topology command ran successfully.
        ```

---

6. Create the instance by **executing** the following code block:

    ``` shell
    cpd-cli manage setup-instance \
    --release=${VERSION} \
    --license_acceptance=true \
    --cpd_operator_ns=${PROJECT_CPD_INST_OPERATORS} \
    --cpd_instance_ns=${PROJECT_CPD_INST_OPERANDS} \
    --block_storage_class=${STG_CLASS_BLOCK} \
    --file_storage_class=${STG_CLASS_FILE} \
    --run_storage_tests=true
    ```

    !!! warning ""
        This operation will take approximately **45 minutes** to complete, after which the console will return:
        ``` shell
        [SUCCESS] The cpd management server was successfully created in the cpd-watsonx project
        [SUCCESS] 2025-03-18T00:09:51.194282Z You may find output and logs in the <REDACTED> directory.
        [SUCCESS] 2025-03-18T00:09:51.194342Z The setup-instance command ran successfully.
        ```

    !!! tip ""
        Examine the last series of console messages just prior to the three `[SUCCESS]` statements made after the execution of *Step 6*. **Record** the *name* of the last deployment made to the cluster just prior to those `[SUCCESS]` statements. Save this information to a notepad for future reference.

---

## **iii. Next steps**

With IBM Software Hub now successfully deployed on the OCP cluster, the environment is primed for the installation of IBM watsonx Code Assistant.

??? note "TROUBLESHOOTING: LOGGING IN AND SESSION TIMEOUTS"
    Be aware that SSH connections made over Terminal will time out after a long period of inactivity or due to a connection error. If you need to log back into the bastion terminal, follow the procedure below. Replace the `<BASTION_PWD>` placeholder with the password specific to *your* environment.

    1. Log back into the bastion node:

        ``` shell
        ssh itzuser@api.67828ca5e432cac47ccc4230.ocp.techzone.ibm.com -p 40222 <BASTION_PWD>
        ```
    
    2. Engage the `sudo` (privileged access) session:

        ``` shell
        sudo bash
        ```

    3. Source the environment variables stored in `cpd_vars.sh`:

        ``` shell
        source cpd_vars.sh
        ```

    4. Log back into OpenShift:

        ``` shell
        ${OC_LOGIN}
        ```

    5. Log back into `cpd-cli`:

        ``` shell
        ${CPDM_OC_LOGIN}
        ```